---
title: "PracMaLearnAssignment"
author: "Helen Zhang"
date: "Sunday, May 24, 2015"
output: html_document
---

This is the assignment for the cousera class "Practical Machine Learning" from Johns Hokpikns University.
The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har.

```{r}
library(caret)
##extract data from file
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
names(training)
```

As checked from the table above, the first columns are about name, window and time, which should not be considered as predictors in the final model if we want to ensure the robustness. And the columns with too many "NAs" (>90%) shall be cleaned as well.

```{r}
##define a function to clean the data.
trim <- function(data){
    for(i in 7:1){
        data <- data[,-i]
        }
    for(i in 152:1){
        if(mean(is.numeric(data[,i]))!=1|mean(is.na(data[,i]))>0.9){
            data <- data[,-i]
            }
        }
    data
}
##trim training and testing data.
training <- trim(training)
testing <- trim(testing)
```

Then we divide the training set into 3 folds and prepare the data for cross-vaidation.

```{r}
folds <- createFolds(training$classe,k=3,list=TRUE,returnTrain=TRUE)
```

Since the goal is to divide the samples into 5 levels, we first tested on "prediction tree".

```{r}
##decision tree
error <- vector()
for(i in 1:3){
  trainSet <- training[folds[[i]],]
  testSet <- training[-folds[[i]],]
  modFit <- train(trainSet$classe~.,method="rpart",data=trainSet)
  conMatrix <- confusionMatrix(testSet$classe,predict(modFit,testSet))
  print(conMatrix)
  error[i] <- 1-as.numeric(conMatrix$overall[1])
}
paste("the expected error for this model is",mean(error),sep=" ")
```

And then "random forests".

```{r}
##random forests
for(i in 1:3){
  trainSet <- training[folds[[i]],]
  testSet <- training[-folds[[i]],]
  modFit <- train(trainSet$classe~.,method="rf",data=trainSet)
  conMatrix <- confusionMatrix(testSet$classe,predict(modFit,testSet))
  print(conMatrix)
  error[i] <- 1-as.numeric(conMatrix$overall[1])
}
paste("the expected error for this model is",mean(error),sep=" ")
```

Since the average accuracy of "random forests" is higher than "decision tree", so we decided to use the former. And the expected out of sample error is calculated above.

```{r}
##prediction of the testing data.
modFit <- train(training$classe~.,method="rf",data=training)
predict(modFit,testing)
```